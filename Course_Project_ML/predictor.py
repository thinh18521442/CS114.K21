import pandas as pd
import numpy as np
import re
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.externals import joblib 
from gensim.models import KeyedVectors
from pyvi import ViTokenizer
from gensim.test.utils import datapath


def predict(text):
    
    """This function predicts if a sentence is sarcastic or not."""
    
    data = text
        
    data = re.sub(r'([A-Z])\1+', lambda m: m.group(1).upper(), data, flags=re.IGNORECASE)
    data = data.lower()
    replace_list = {
        'รฒa': 'oร', 'รณa': 'oรก', 'แปa': 'oแบฃ', 'รตa': 'oรฃ', 'แปa': 'oแบก', 'รฒe': 'oรจ', 'รณe': 'oรฉ','แปe': 'oแบป',
        'รตe': 'oแบฝ', 'แปe': 'oแบน', 'รนy': 'uแปณ', 'รบy': 'uรฝ', 'แปงy': 'uแปท', 'ลฉy': 'uแปน','แปฅy': 'uแปต', 'uแบฃ': 'แปงa',
        'aฬ': 'แบฃ', 'รดฬ': 'แป', 'uยด': 'แป','รดฬ': 'แป', 'รดฬ': 'แป', 'รดฬ': 'แป', 'รขฬ': 'แบฅ', 'รขฬ': 'แบซ', 'รขฬ': 'แบฉ',
        'รขฬ': 'แบง', 'oฬ': 'แป', 'รชฬ': 'แป','รชฬ': 'แป', 'ฤฬ': 'แบฏ', 'uฬ': 'แปง', 'รชฬ': 'แบฟ', 'ฦกฬ': 'แป', 'iฬ': 'แป',
        'eฬ': 'แบป', 'รk': u' ร ','aห': 'ร', 'iห': 'รฌ', 'ฤยด': 'แบฏ','ฦฐฬ': 'แปญ', 'eห': 'แบฝ', 'yห': 'แปน', 'aยด': 'รก',
        'รด kรชi': ' ok ', 'okie': ' ok ', ' o kรช ': ' ok ', ':)' : 'positive', ':(' : 'negative',
        'okey': ' ok ', 'รดkรช': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okรช':' ok ',
        ' tks ': u' cรกm ฦกn ', 'thks': u' cรกm ฦกn ', 'thanks': u' cรกm ฦกn ', 'ths': u' cรกm ฦกn ', 'thank': u' cรกm ฦกn ',
        'โญ': 'star ', '*': 'star ', '๐': 'star ', '๐': u' positive ',
        'kg ': u' khรดng ','not': u' khรดng ', u' kg ': u' khรดng ', '"k ': u' khรดng ',' kh ':u' khรดng ','kรด':u' khรดng ','hok':u' khรดng ',' kp ': u' khรดng phแบฃi ',u' kรด ': u' khรดng ', '"ko ': u' khรดng ', u' ko ': u' khรดng ', u' k ': u' khรดng ', 'khong': u' khรดng ', u' hok ': u' khรดng ',
        'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',
        ' lol ': ' nagative ',' cc ': ' nagative ','cute': u' dแป thฦฐฦกng ','huhu': ' nagative ', ' vs ': u' vแปi ', 'wa': ' quรก ', 'wรก': u' quรก', 'j': u' gรฌ ', 'โ': ' ',
        ' sz ': u' cแปก ', 'size': u' cแปก ', u' ฤx ': u' ฤฦฐแปฃc ', 'dk': u' ฤฦฐแปฃc ', 'dc': u' ฤฦฐแปฃc ', 'ฤk': u' ฤฦฐแปฃc ',
        'ฤc': u' ฤฦฐแปฃc ','authentic': u' chuแบฉn chรญnh hรฃng ',u' aut ': u' chuแบฉn chรญnh hรฃng ', u' auth ': u' chuแบฉn chรญnh hรฃng ', 'thick': u' positive ', 'store': u' cแปญa hรng ',
        'shop': u' cแปญa hรng ', 'sp': u' sแบฃn phแบฉm ', 'gud': u' tแปt ','god': u' tแปt ','wel done':' tแปt ', 'good': u' tแปt ', 'gรบt': u' tแปt ',
        'sแบฅu': u' xแบฅu ','gut': u' tแปt ', u' tot ': u' tแปt ', u' nice ': u' tแปt ', 'perfect': 'rแบฅt tแปt', 'bt': u' bรฌnh thฦฐแปng ',
        'time': u' thแปi gian ', 'qรก': u' quรก ', u' ship ': u' giao hรng ', u' m ': u' mรฌnh ', u' mik ': u' mรฌnh ',
        'รชฬ': 'แป', 'product': 'sแบฃn phแบฉm', 'quality': 'chแบฅt lฦฐแปฃng','chat':' chแบฅt ', 'excelent': 'hoรn hแบฃo', 'bad': 'tแป','fresh': ' tฦฐฦกi ','sad': ' tแป ',
        'date': u' hแบกn sแปญ dแปฅng ', 'hsd': u' hแบกn sแปญ dแปฅng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hรng ',u' sรญp ': u' giao hรng ',
        'beautiful': u' ฤแบนp tuyแปt vแปi ', u' tl ': u' trแบฃ lแปi ', u' r ': u' rแปi ', u' shopE ': u' cแปญa hรng ',u' order ': u' ฤแบทt hรng ',
        'chแบฅt lg': u' chแบฅt lฦฐแปฃng ',u' sd ': u' sแปญ dแปฅng ',u' dt ': u' ฤiแปn thoแบกi ',u' nt ': u' nhแบฏn tin ',u' tl ': u' trแบฃ lแปi ',u' sรi ': u' xรi ',u'bjo':u' bao giแป ',
        'thik': u' thรญch ',u' sop ': u' cแปญa hรng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rแบฅt ',u'quแบฃ ng ':u' quแบฃng  ',
        'dep': u' ฤแบนp ',u' xau ': u' xแบฅu ','delicious': u' ngon ', u'hรg': u' hรng ', u'qแปงa': u' quแบฃ ',
        'iu': u' yรชu ','fake': u' giแบฃ mแบกo ', 'trl': 'trแบฃ lแปi', '><': u' positive ',
        ' por ': u' tแป ',' poor ': u' tแป ', 'ib':u' nhแบฏn tin ', 'rep':u' trแบฃ lแปi ',u'fback':' feedback ','fedback':' feedback ',
        #dฦฐแปi 3* quy vแป 1*, trรชn 3* quy vแป 5*
        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ',
        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ',
        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ',
    }
    for k ,v in replace_list.items():
      data = data.replace(k,v)
    data = data.replace(",", " ").replace(".", " ") \
        .replace(";", " ").replace("โ", " ") \
        .replace(":", " ").replace("โ", " ") \
        .replace('"', " ").replace("'", " ") \
        .replace("!", " ").replace("?", " ") \
        .replace("-", " ").replace("?", " ")      
    data = data.strip()

    wv_from_bin = KeyedVectors.load_word2vec_format(datapath("baomoi.model.bin"), binary=True)
    vocab = wv_from_bin.wv.vocab

    data = ViTokenizer.tokenize(data)
    T = []
    words = data.split(' ')
    vec_data = np.zeros((400))
    for word in words:
      if word in vocab:
        vec_data += wv_from_bin.wv[word]
    vec_data.reshape(1,-1)
    l = vec_data.tolist()    
    T.append(l)
    T = np.array(T)
    with open('saved_model.pkl', 'rb') as f:
      model = joblib.load(f)
    prediction = model.predict(T)
    return int(prediction[0])

